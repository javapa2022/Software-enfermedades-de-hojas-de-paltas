# -*- coding: utf-8 -*-
"""palta.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aKm2XV330J6w1lwEmQG09HKhIF9s-vf-
"""

!pip install streamlit tensorflow keras opencv-python matplotlib seaborn pandas numpy scikit-learn plotly keras-tuner pyngrok fpdf

!git clone https://github.com/javapa2022/Software-enfermedades-de-hojas-de-paltas.git

import os
import shutil
from tqdm import tqdm

def copy_dataset(input_dir, output_dir):
    os.makedirs(output_dir, exist_ok=True)
    subsets = ['train', 'valid', 'test']
    classes = ['Healthy', 'Disease']

    for subset in subsets:
        for label in classes:
            input_class_dir = os.path.join(input_dir, subset, label)
            output_class_dir = os.path.join(output_dir, subset, label)
            os.makedirs(output_class_dir, exist_ok=True)

            print(f"Copiando clase '{label}' del conjunto '{subset}'")
            for file_name in tqdm(os.listdir(input_class_dir)):
                input_path = os.path.join(input_class_dir, file_name)
                output_path = os.path.join(output_class_dir, file_name)

                try:
                    shutil.copy2(input_path, output_path)
                except Exception as e:
                    print(f"Error copiando {file_name}: {e}")

if __name__ == "__main__":
    base_input_dir = "/content/Software-enfermedades-de-hojas-de-paltas/Avocado Augmneted_Dataset"
    base_output_dir = "/content/Avocado Augmneted_Dataset"

    copy_dataset(base_input_dir, base_output_dir)

"""# **Modelos (model_utils.py)**

"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile model_utils.py
# import tensorflow as tf
# from tensorflow.keras.models import Model
# from tensorflow.keras.layers import (
#     Input, Conv2D, MaxPooling2D, GlobalAveragePooling2D,
#     Dense, Dropout, BatchNormalization
# )
# from tensorflow.keras.optimizers import Adam
# import numpy as np
# from tensorflow.keras.applications import DenseNet121, EfficientNetB0
# 
# def load_models():
#     models = {}
# 
#     # CNN 2D Personalizada para RGB
#     input_shape = (224, 224, 3)
#     inputs = Input(input_shape)
#     x = Conv2D(32, (3,3), activation='relu')(inputs)
#     x = MaxPooling2D((2,2))(x)
#     x = BatchNormalization()(x)
# 
#     x = Conv2D(64, (3,3), activation='relu')(x)
#     x = MaxPooling2D((2,2))(x)
#     x = BatchNormalization()(x)
# 
#     x = Conv2D(128, (3,3), activation='relu')(x)
#     x = MaxPooling2D((2,2))(x)
#     x = BatchNormalization()(x)
# 
#     x = GlobalAveragePooling2D()(x)
#     x = Dense(256, activation='relu')(x)
#     x = Dropout(0.5)(x)
#     outputs = Dense(1, activation='sigmoid')(x)
# 
#     model = Model(inputs=inputs, outputs=outputs)
#     model.compile(
#         optimizer=Adam(learning_rate=0.0005),
#         loss='binary_crossentropy',
#         metrics=['accuracy', tf.keras.metrics.AUC(name='auc'),
#                  tf.keras.metrics.Precision(name='precision'),
#                  tf.keras.metrics.Recall(name='recall')]
#     )
#     models['CNN 2D Personalizada'] = model
# 
#     # DenseNet121
#     densenet_input = Input(shape=(224, 224, 3))
#     base_densenet = DenseNet121(weights='imagenet', include_top=False, input_tensor=densenet_input)
#     base_densenet.trainable = False
# 
#     x = base_densenet.output
#     x = GlobalAveragePooling2D()(x)
#     x = Dense(256, activation='relu')(x)
#     x = Dropout(0.5)(x)
#     output = Dense(1, activation='sigmoid')(x)
#     densenet_model = Model(inputs=densenet_input, outputs=output)
#     densenet_model.compile(
#         optimizer=Adam(learning_rate=0.0005),
#         loss='binary_crossentropy',
#         metrics=['accuracy', tf.keras.metrics.AUC(name='auc'),
#                  tf.keras.metrics.Precision(name='precision'),
#                  tf.keras.metrics.Recall(name='recall')]
#     )
#     models["DenseNet121"] = densenet_model
# 
#     # Modelo 3: EfficientNetB0
#     efficient_input = Input(shape=(224, 224, 3))
#     base_efficient = EfficientNetB0(weights='imagenet', include_top=False, input_tensor=efficient_input)
#     base_efficient.trainable = False
# 
#     x = base_efficient.output
#     x = GlobalAveragePooling2D()(x)
#     x = Dense(256, activation='relu')(x)
#     x = Dropout(0.5)(x)
#     output = Dense(1, activation='sigmoid')(x)
#     efficient_model = Model(inputs=efficient_input, outputs=output)
#     efficient_model.compile(
#         optimizer=Adam(learning_rate=0.0005),
#         loss='binary_crossentropy',
#         metrics=['accuracy', tf.keras.metrics.AUC(name='auc'),
#                  tf.keras.metrics.Precision(name='precision'),
#                  tf.keras.metrics.Recall(name='recall')]
#     )
#     models["EfficientNetB0"] = efficient_model
# 
#     return models
# 
# def predict_image(model, image):
#     if image.shape[-1] != 3:
#         raise ValueError("La imagen debe tener 3 canales RGB.")
#     image = np.expand_dims(image, axis=0)
#     prediction = model.predict(image)
#     confidence = float(prediction[0][0])
#     diagnosis = 1 if confidence > 0.5 else 0
#     heatmap = generate_saliency_map(model, image[0])
#     return diagnosis, confidence, heatmap
# 
# def generate_saliency_map(model, image):
#     if image.ndim == 3:
#         image_tensor = tf.convert_to_tensor(np.expand_dims(image, axis=0), dtype=tf.float32)
#     elif image.ndim == 4:
#         image_tensor = tf.convert_to_tensor(image, dtype=tf.float32)
#     else:
#         raise ValueError("Imagen debe tener 3 (HWC) o 4 (BHWC) dimensiones.")
# 
#     with tf.GradientTape() as tape:
#         tape.watch(image_tensor)
#         prediction = model(image_tensor)
# 
#     gradients = tape.gradient(prediction, image_tensor)
#     saliency_map = tf.reduce_max(tf.abs(gradients), axis=-1)[0].numpy()
# 
#     if saliency_map.max() != saliency_map.min():
#         saliency_map = (saliency_map - saliency_map.min()) / (saliency_map.max() - saliency_map.min())
#     else:
#         saliency_map = np.zeros_like(saliency_map)
# 
#     return saliency_map
#

"""# **Preprocesamiento (preprocessing.py)**"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile preprocessing.py
# from skimage.io import imread
# from skimage.transform import resize
# from skimage.exposure import equalize_adapthist
# import numpy as np
# from skimage import img_as_ubyte
# import cv2
# 
# def preprocess_image(image, target_size=(224, 224)):
#         image = img_as_ubyte(image)
#         image = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)
#         l, a, b = cv2.split(image)
#         clahe = cv2.createCLAHE(clipLimit=2.5, tileGridSize=(8, 8))
#         cl = clahe.apply(l)
#         limg = cv2.merge((cl, a, b))
#         image = cv2.cvtColor(limg, cv2.COLOR_LAB2RGB)
# 
#         image = image.astype(np.float32) / 255.0
#         return image
# 
# def load_and_preprocess_image(image_path, target_size=(224, 224)):
#     image = imread(image_path)  # RGB
#     image_original = resize(image, target_size, mode='reflect', anti_aliasing=True)
#     image_preprocessed = preprocess_image(image, target_size)
#     return image_preprocessed, image_original
#

"""# **Entrenamiento (train_avocado.py)**

"""

#%%writefile train_avocado.py
import tensorflow as tf
import os
import numpy as np
import pandas as pd
from datetime import datetime
from sklearn.utils.class_weight import compute_class_weight
from collections import Counter
from model_utils import load_models
from skimage.io import imread
from skimage.transform import resize
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard
from skimage import img_as_ubyte
import cv2

# Cargar dataset

def load_dataset_avocado(data_dir):
    def get_data(subset):
        subset_dir = os.path.join(data_dir, subset)
        disease_cases = [os.path.join(subset_dir, 'Disease', f) for f in os.listdir(os.path.join(subset_dir, 'Disease'))]
        healthy_cases = [os.path.join(subset_dir, 'Healthy', f) for f in os.listdir(os.path.join(subset_dir, 'Healthy'))]
        disease_labels = [1] * len(disease_cases)
        healthy_labels = [0] * len(healthy_cases)
        cases = disease_cases + healthy_cases
        labels = disease_labels + healthy_labels
        return cases, labels

    train_cases, train_labels = get_data('train')
    val_cases, val_labels = get_data('valid')
    test_cases, test_labels = get_data('test')

    return (train_cases, train_labels), (val_cases, val_labels), (test_cases, test_labels)

def mostrar_distribucion_clases(train_labels, val_labels):
    print("\nDistribuci贸n de clases:")
    print(f" - Train: {Counter(train_labels)}")
    print(f" - Valid: {Counter(val_labels)}")

# Generador de datos

class AvocadoImageGenerator(tf.keras.utils.Sequence):
    def __init__(self, cases, labels, batch_size=32, image_size=(224, 224), augment=False, **kwargs):
        super().__init__(**kwargs)
        self.cases = cases
        self.labels = labels
        self.batch_size = batch_size
        self.image_size = image_size
        self.augment = augment
        self.indices = np.arange(len(self.cases))

        self.augmenter = ImageDataGenerator(
            rotation_range=10,
            width_shift_range=0.05,
            height_shift_range=0.05,
            zoom_range=0.1,
            horizontal_flip=True,
            fill_mode='reflect'
        ) if augment else None

    def preprocess_image(self, image):
        image = img_as_ubyte(image)
        image = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)
        l, a, b = cv2.split(image)
        clahe = cv2.createCLAHE(clipLimit=2.5, tileGridSize=(8, 8))
        cl = clahe.apply(l)
        limg = cv2.merge((cl, a, b))
        image = cv2.cvtColor(limg, cv2.COLOR_LAB2RGB)
        image = image.astype(np.float32) / 255.0
        return image

    def __len__(self):
        return int(np.ceil(len(self.cases) / self.batch_size))

    def __getitem__(self, index):
        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]
        batch_cases = [self.cases[i] for i in batch_indices]
        batch_labels = [self.labels[i] for i in batch_indices]

        batch_images = []
        batch_labels_clean = []

        for i, path in enumerate(batch_cases):
            try:
                image = imread(path)
                if image is None or image.size == 0:
                    print(f"[ADVERTENCIA] Imagen vac铆a o inv谩lida: {path}")
                    continue
                if np.isnan(image).any():
                    print(f"[ADVERTENCIA] Imagen contiene NaN: {path}")
                    continue
                if len(image.shape) < 2:
                    print(f"[ADVERTENCIA] Imagen con forma inv谩lida: {path} -> {image.shape}")
                    continue

                image = resize(image, self.image_size, mode='reflect', anti_aliasing=True)
                image = self.preprocess_image(image)
                batch_images.append(image)
                batch_labels_clean.append(batch_labels[i])

            except Exception as e:
                print(f"[ERROR] Fallo al procesar imagen: {path} -> {e}")
                continue

        if not batch_images:
            raise ValueError("No se pudieron procesar im谩genes v谩lidas en este batch.")

        batch_images = np.array(batch_images, dtype=np.float32)
        batch_labels = np.array(batch_labels_clean, dtype=np.float32)

        if self.augmenter:
            aug_iter = self.augmenter.flow(batch_images, batch_labels, batch_size=len(batch_images), shuffle=False)
            batch_images, batch_labels = next(aug_iter)

        return batch_images, batch_labels

    def on_epoch_end(self):
        np.random.shuffle(self.indices)


# Entrenamiento

def train_model(model, train_generator, val_generator, epochs, model_name='avocado_model', class_weight=None):
    callbacks = [
        ModelCheckpoint(f'models/{model_name}.keras', monitor='val_auc', save_best_only=True, mode='max', verbose=1),
        EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1),
        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6, verbose=1),
        TensorBoard(log_dir=f'logs/{model_name}_{datetime.now().strftime("%Y%m%d-%H%M%S")}')
    ]

    history = model.fit(
        train_generator,
        validation_data=val_generator,
        epochs=epochs,
        callbacks=callbacks,
        class_weight=class_weight,
        verbose=1
    )

    pd.DataFrame(history.history).to_csv(f'models/{model_name}_history.csv', index=False)
    return history

# Ejecuci贸n principal

if __name__ == "__main__":
    data_dir = '/content/Avocado Augmneted_Dataset'
    os.makedirs('models', exist_ok=True)
    os.makedirs('logs', exist_ok=True)

    (train_cases, train_labels), (val_cases, val_labels), (test_cases, test_labels) = load_dataset_avocado(data_dir)
    mostrar_distribucion_clases(train_labels, val_labels)

    class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(train_labels), y=train_labels)
    class_weight = dict(enumerate(class_weights))

    models = load_models()

    for modelo_objetivo in ["CNN 2D Personalizada","EfficientNetB0","DenseNet121"]:
        print(f"\nEntrenando modelo: {modelo_objetivo}")
        train_gen = AvocadoImageGenerator(train_cases, train_labels, batch_size=32, augment=True)
        val_gen = AvocadoImageGenerator(val_cases, val_labels, batch_size=32, augment=False)

        train_model(
            models[modelo_objetivo],
            train_gen,
            val_gen,
            epochs=50,
            model_name=f"{modelo_objetivo.lower().replace(' ', '_')}_avocado",
            class_weight=class_weight
        )


    for modelo_objetivo in ["CNN 2D Personalizada","EfficientNetB0","DenseNet121"]:
        print(f"\nEntrenando modelo: {modelo_objetivo}")
        train_gen = AvocadoImageGenerator(train_cases, train_labels, batch_size=32, augment=True)
        val_gen = AvocadoImageGenerator(val_cases, val_labels, batch_size=32, augment=False)

        train_model(
            models[modelo_objetivo],
            train_gen,
            val_gen,
            epochs=50,
            model_name=f"{modelo_objetivo.lower().replace(' ', '_')}_avocado",
            class_weight=class_weight
        )

"""# **Aplicacion en Streamlit (app.py)**"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import os
# import matplotlib.pyplot as plt
# from model_utils import predict_image
# from preprocessing import load_and_preprocess_image
# from report_utils import generate_pdf_report, generate_comparison_report
# from tensorflow.keras.models import load_model
# from metrics_utils import evaluate_on_dataset
# import time
# import glob
# import io
# 
# st.set_page_config(
#     page_title="Sistema de Diagn贸stico de Enfermedades de Hoja de Palta",
#     page_icon="",
#     layout="wide"
# )
# 
# st.title("Sistema Inteligente de Diagn贸stico de Enfermedades de Hoja de Palta")
# st.markdown("""
# Este sistema utiliza redes neuronales convolucionales para analizar im谩genes de hojas de palta
# y detectar signos de enfermedades.
# """)
# 
# MODEL_PATHS = {
#     "CNN 2D Personalizada": "models/cnn_2d_personalizada_avocado.keras",
#     "DenseNet121": "models/densenet121_avocado.keras",
#     "EfficientNetB0": "models/efficientnetb0_avocado.keras"
# }
# 
# @st.cache_resource
# def load_selected_model(model_name):
#     model_path = MODEL_PATHS.get(model_name)
#     if model_path and os.path.exists(model_path):
#         return load_model(model_path)
#     else:
#         st.error(f"No se encontr贸 el modelo: {model_path}")
#         st.stop()
# 
# st.sidebar.header("Configuraci贸n")
# model_names = list(MODEL_PATHS.keys())
# selected_model_name = st.sidebar.selectbox("Modelo a utilizar", model_names)
# 
# confidence_threshold = st.sidebar.slider(
#     "Umbral de confianza para diagn贸stico",
#     min_value=0.1, max_value=0.99, value=0.5, step=0.01
# )
# 
# model = load_selected_model(selected_model_name)
# 
# DATASET_PATH = "/content/Avocado Augmneted_Dataset/valid"
# 
# st.header("Carga de Imagen")
# upload_option = st.radio("Seleccione el tipo de entrada", ["Subir imagen JPG/PNG", "Usar ejemplo"])
# 
# uploaded_file = None
# 
# if upload_option == "Subir imagen JPG/PNG":
#     uploaded_file = st.file_uploader("Suba una imagen de hoja", type=["png", "jpg", "jpeg"])
# else:
#     class_folders = [f for f in os.listdir(DATASET_PATH) if os.path.isdir(os.path.join(DATASET_PATH, f))]
# 
#     selected_class = st.selectbox("Seleccione clase de ejemplo", class_folders)
# 
#     selected_folder = os.path.join(DATASET_PATH, selected_class)
#     class_images = glob.glob(os.path.join(selected_folder, "*.png")) + glob.glob(os.path.join(selected_folder, "*.jpg"))
# 
#     if class_images:
#         file_names = [os.path.basename(f) for f in class_images]
#         file_choice = st.selectbox("Seleccione imagen", file_names)
# 
#         if file_choice:
#             uploaded_file = os.path.join(selected_folder, file_choice)
#         else:
#             st.warning("Seleccione una imagen v谩lida.")
#     else:
#         st.warning(f"No se encontraron im谩genes en la carpeta '{selected_class}'.")
# 
# if uploaded_file:
#     with st.spinner("Procesando imagen..."):
#         image_preprocessed, image_original = load_and_preprocess_image(uploaded_file)
#         time.sleep(1)
# 
#     st.subheader("Visualizaci贸n de Imagen")
#     col1, col2 = st.columns(2)
#     with col1:
#         st.image(image_original, caption="Imagen Original Redimensionada", use_container_width=True)
#     with col2:
#         st.image(image_preprocessed, caption="Imagen Preprocesada", use_container_width=True)
# 
#     st.header("Resultados del Diagn贸stico")
# 
#     with st.spinner("Analizando imagen..."):
#         prediction, confidence, heatmap = predict_image(model, image_preprocessed)
# 
#     col1, col2, col3 = st.columns(3)
#     with col1:
#         st.metric("Modelo utilizado", selected_model_name)
#     with col2:
#         st.metric("Predicci贸n", "Enferma" if prediction == 1 else "Saludable")
#     with col3:
#         st.metric("Confianza", f"{confidence:.2%}")
# 
#     if confidence < confidence_threshold:
#         st.warning("La confianza es baja. Se recomienda evaluaci贸n adicional.")
#     else:
#         if prediction == 0:
#             st.success("La hoja est谩 saludable.")
#         else:
#             st.error("Se detectaron posibles signos de enfermedad en la hoja.")
# 
#     st.subheader("Mapa de Saliencia (Regiones relevantes)")
#     fig, ax = plt.subplots(figsize=(6,6))
#     ax.imshow(image_original)
#     ax.imshow(heatmap, cmap='jet', alpha=0.5)
#     ax.axis('off')
#     st.pyplot(fig)
# 
# 
# 
# st.subheader("Generar Reporte PDF")
# if st.button(" Generar Reporte PDF"):
#     with st.spinner("Generando reporte..."):
#         pdf_bytes = generate_pdf_report(
#             image_original=image_original,
#             heatmap=heatmap,
#             diagnosis=prediction,
#             confidence=confidence,
#             model_name=selected_model_name
#         )
# 
#     st.download_button(
#         label=" Descargar Reporte PDF",
#         data=pdf_bytes,
#         file_name="reporte_diagnostico_avocado.pdf",
#         mime="application/pdf"
#     )
# 
# 
# 
# st.header("Comparaci贸n de Modelos con Dataset de Validaci贸n")
# 
# if st.button("Evaluar Modelos y Generar Reporte"):
#     with st.spinner("Evaluando modelos..."):
#         test_dir = "/content/Avocado Augmneted_Dataset/valid"
# 
#         metrics_list, comparisons, confusion_matrices = evaluate_on_dataset(test_dir)
# 
#         report_path = generate_comparison_report(metrics_list, ["CNN 2D Personalizada", "DenseNet121", "EfficientNetB0"], comparisons, confusion_matrices)
# 
#         with open(report_path, "rb") as f:
#             st.download_button("  Descargar Reporte de Comparaci贸n", data=f, file_name="comparacion_modelos.pdf", mime="application/pdf")
# 
#     st.success("Evaluaci贸n y reporte generados con 茅xito.")
#

"""# **M茅tricas y PDF (metrics_utils.py && report_utils.py)**"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile metrics_utils.py
# import numpy as np
# from sklearn.metrics import confusion_matrix, classification_report
# from scipy.stats import chi2
# from tensorflow.keras.models import load_model
# import matplotlib.pyplot as plt
# import os
# from tqdm import tqdm
# import seaborn as sns
# from skimage.io import imread
# 
# def matthews_corrcoef(cm):
#     tp, fp, fn, tn = cm[1][1], cm[0][1], cm[1][0], cm[0][0]
#     numerator = (tp * tn) - (fp * fn)
#     denominator = np.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))
#     return numerator / denominator if denominator != 0 else 0
# 
# def mcnemar_test(y_true, y_model1, y_model2):
#     table = np.zeros((2, 2))
#     for true, pred1, pred2 in zip(y_true, y_model1, y_model2):
#         if pred1 == true and pred2 != true:
#             table[0][1] += 1
#         elif pred1 != true and pred2 == true:
#             table[1][0] += 1
#     if table[0][1] + table[1][0] > 25:
#         statistic = (np.abs(table[0][1] - table[1][0]) - 1) ** 2 / (table[0][1] + table[1][0])
#     else:
#         statistic = (np.abs(table[0][1] - table[1][0])) ** 2 / (table[0][1] + table[1][0])
#     p_value = 1 - chi2.cdf(statistic, df=1)
#     return statistic, p_value
# 
# def evaluate_on_dataset(test_dir):
#     def load_data():
#         cases, labels = [], []
#         for label_name, label in [('Healthy', 0), ('Disease', 1)]:
#             folder = os.path.join(test_dir, label_name)
#             for img_file in os.listdir(folder):
#                 img = imread(os.path.join(folder, img_file)).astype(np.float32) / 255.0
#                 cases.append(img)
#                 labels.append(label)
#         X = np.array(cases)
#         y = np.array(labels)
#         return X, y
# 
#     X, y_true = load_data()
# 
#     models = {
#         "CNN 2D Personalizada": load_model("models/cnn_2d_personalizada_avocado.keras"),
#         "DenseNet121": load_model("models/densenet121_avocado.keras"),
#         "EfficientNetB0": load_model("models/efficientnetb0_avocado.keras")
#     }
# 
#     metrics_list = []
#     predictions_per_model = []
#     confusion_matrices = []
# 
#     for name, model in models.items():
#         if model.input_shape[-1] == 3 and X.shape[-1] == 1:
#             X_processed = np.repeat(X, 3, axis=-1)
#         else:
#             X_processed = X
# 
#         preds = model.predict(X_processed, batch_size=32).flatten()
#         y_pred = (preds > 0.5).astype(int)
#         predictions_per_model.append(y_pred)
# 
#         cm = confusion_matrix(y_true, y_pred)
#         report = classification_report(y_true, y_pred, target_names=['Healthy', 'Disease'], output_dict=True)
# 
#         metrics_list.append({
#             'model': name,
#             'accuracy': report['accuracy'],
#             'sensitivity': report['Disease']['recall'],
#             'specificity': report['Healthy']['recall'],
#             'f1': report['Disease']['f1-score'],
#             'mcc': matthews_corrcoef(cm)
#         })
# 
#         plt.figure(figsize=(4, 4))
#         sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,
#                     xticklabels=['Healthy', 'Disease'],
#                     yticklabels=['Healthy', 'Disease'])
#         plt.title(f'Matriz de Confusi贸n - {name}')
#         plt.xlabel('Predicho')
#         plt.ylabel('Real')
# 
#         cm_path = f'cm_{name.replace(" ", "_").lower()}.png'
#         plt.tight_layout()
#         plt.savefig(cm_path)
#         plt.close()
# 
#         confusion_matrices.append(cm_path)
# 
#     comparisons = {}
#     comparisons['0_1'] = mcnemar_test(y_true, predictions_per_model[0], predictions_per_model[1])
#     comparisons['0_2'] = mcnemar_test(y_true, predictions_per_model[0], predictions_per_model[2])
#     comparisons['1_2'] = mcnemar_test(y_true, predictions_per_model[1], predictions_per_model[2])
# 
#     return metrics_list, comparisons, confusion_matrices

# Commented out IPython magic to ensure Python compatibility.
# %%writefile report_utils.py
# from fpdf import FPDF
# from PIL import Image
# import numpy as np
# import matplotlib.pyplot as plt
# import os
# import io
# 
# def generate_pdf_report(image_original, heatmap, diagnosis, confidence, model_name):
#     combined_path = "combined_temp.png"
#     fig, axes = plt.subplots(1, 2, figsize=(8, 4))
# 
#     axes[0].imshow(image_original.astype(np.float32))
#     axes[0].axis("off")
#     axes[0].set_title("Imagen Original")
# 
#     axes[1].imshow(image_original.astype(np.float32))
#     axes[1].imshow(heatmap, cmap='jet', alpha=0.5)
#     axes[1].axis("off")
#     axes[1].set_title("Mapa de Saliencia")
# 
#     plt.tight_layout()
#     plt.savefig(combined_path)
#     plt.close()
# 
#     diagnosis_text = "ENFERMA" if diagnosis == 1 else "SALUDABLE"
# 
#     pdf = FPDF()
#     pdf.add_page()
#     pdf.set_font("Arial", size=14)
#     pdf.cell(200, 10, txt="Reporte de Diagn贸stico de Hoja de Palta", ln=1, align='C')
# 
#     pdf.set_font("Arial", size=12)
#     pdf.ln(10)
#     pdf.cell(200, 10, txt=f"Modelo utilizado: {model_name}", ln=1)
#     pdf.cell(200, 10, txt=f"Diagn贸stico: {diagnosis_text}", ln=1)
#     pdf.cell(200, 10, txt=f"Confianza: {confidence:.2f}", ln=1)
# 
#     pdf.image(combined_path, x=30, y=60, w=150)
# 
#     os.remove(combined_path)
# 
#     #  Devuelve el contenido del PDF como bytes
#     return pdf.output(dest='S').encode('latin-1')
# 
# def generate_comparison_report(metrics_list, model_names, comparisons, confusion_matrices, output_path="comparison_report_avocado.pdf"):
#     """
#     Genera un reporte PDF comparando m茅tricas, pruebas estad铆sticas y mostrando las matrices de confusi贸n.
#     """
# 
#     pdf = FPDF()
#     pdf.add_page()
# 
#     # T铆tulo
#     pdf.set_font("Arial", 'B', 16)
#     pdf.cell(0, 10, txt="Reporte Comparativo de Modelos - Hoja de Palta", ln=True, align='C')
#     pdf.ln(10)
# 
#     # M茅tricas
#     pdf.set_font("Arial", 'B', 12)
#     pdf.cell(0, 10, txt="M茅tricas de Evaluaci贸n por Modelo", ln=True)
#     pdf.set_font("Arial", 'B', 10)
# 
#     headers = ['Modelo', 'Accuracy', 'Sensibilidad', 'Especificidad', 'F1-Score', 'MCC']
#     col_widths = [50, 25, 30, 30, 25, 25]
# 
#     for header, width in zip(headers, col_widths):
#         pdf.cell(width, 8, header, border=1, align='C')
#     pdf.ln()
# 
#     pdf.set_font("Arial", '', 10)
#     for metrics in metrics_list:
#         pdf.cell(col_widths[0], 8, metrics['model'], border=1)
#         pdf.cell(col_widths[1], 8, f"{metrics['accuracy']:.3f}", border=1, align='C')
#         pdf.cell(col_widths[2], 8, f"{metrics['sensitivity']:.3f}", border=1, align='C')
#         pdf.cell(col_widths[3], 8, f"{metrics['specificity']:.3f}", border=1, align='C')
#         pdf.cell(col_widths[4], 8, f"{metrics['f1']:.3f}", border=1, align='C')
#         pdf.cell(col_widths[5], 8, f"{metrics['mcc']:.3f}", border=1, align='C')
#         pdf.ln()
# 
#     # Comparaciones estad铆sticas (McNemar)
#     pdf.ln(10)
#     pdf.set_font("Arial", 'B', 12)
#     pdf.cell(0, 10, txt="Comparaciones Estad铆sticas (Prueba de McNemar)", ln=True)
#     pdf.set_font("Arial", '', 10)
# 
#     comparaciones_nombres = {'0_1': (model_names[0], model_names[1]),
#                              '0_2': (model_names[0], model_names[2]),
#                              '1_2': (model_names[1], model_names[2])}
# 
#     pdf.ln(5)
#     pdf.set_font("Arial", 'B', 10)
#     pdf.cell(60, 8, "Comparaci贸n", border=1, align='C')
#     pdf.cell(40, 8, "Estad铆stico", border=1, align='C')
#     pdf.cell(40, 8, "p-valor", border=1, align='C')
#     pdf.ln()
# 
#     pdf.set_font("Arial", '', 10)
#     for key, (name1, name2) in comparaciones_nombres.items():
#         stat, p_value = comparisons[key]
#         comparacion = f"{name1} vs {name2}"
#         pdf.cell(60, 8, comparacion, border=1)
#         pdf.cell(40, 8, f"{stat:.3f}", border=1, align='C')
#         pdf.cell(40, 8, f"{p_value:.5f}", border=1, align='C')
#         pdf.ln()
# 
#     # Matrices de confusi贸n
#     pdf.add_page()
#     pdf.set_font("Arial", 'B', 12)
#     pdf.cell(0, 10, txt="Matrices de Confusi贸n", ln=True)
#     pdf.ln(5)
# 
#     for model_name, cm_path in zip(model_names, confusion_matrices):
#         pdf.cell(0, 10, txt=f"Modelo: {model_name}", ln=True)
#         pdf.image(cm_path, x=30, w=150)
#         pdf.ln(10)
# 
#     pdf.output(output_path)
#     print(f"Reporte comparativo generado correctamente en: {output_path}")
#     return output_path
#

from pyngrok import ngrok, conf
conf.get_default().auth_token = "2xFZJFASHUPcQvQsjAAAwRnlErT_71GkkXPeKEkEj4ncoiTfL"

public_url = ngrok.connect(addr="8501", proto="http")
print(f"Tu app est谩 en: {public_url}")

!streamlit run app.py